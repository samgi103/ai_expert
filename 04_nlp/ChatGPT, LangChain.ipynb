{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1TQjxsxFNKFERUJe2gHghiCUW1hOXp4P8","timestamp":1687486261406}],"gpuType":"T4","toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Install Pacakges!"],"metadata":{"id":"zyG2sJRnO-Oi"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H8IqGG4mHXhX","executionInfo":{"status":"ok","timestamp":1687502766176,"user_tz":-540,"elapsed":33192,"user":{"displayName":"백삼기","userId":"07015587273030351036"}},"outputId":"1fcf9a6c-0008-4283-aa7c-111134d48565"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting openai\n","  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n","Collecting aiohttp (from openai)\n","  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n","Collecting multidict<7.0,>=4.5 (from aiohttp->openai)\n","  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai)\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting yarl<2.0,>=1.0 (from aiohttp->openai)\n","  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->openai)\n","  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->openai)\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.8 yarl-1.9.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting langchain\n","  Downloading langchain-0.0.209-py3-none-any.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.10)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.4)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n","Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain)\n","  Downloading dataclasses_json-0.5.8-py3-none-any.whl (26 kB)\n","Collecting langchainplus-sdk>=0.0.13 (from langchain)\n","  Downloading langchainplus_sdk-0.0.16-py3-none-any.whl (24 kB)\n","Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n","Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain)\n","  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.7)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.27.1)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Collecting marshmallow<4.0.0,>=3.3.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n","  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting marshmallow-enum<2.0.0,>=1.5.1 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n","  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n","Collecting typing-inspect>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Installing collected packages: mypy-extensions, marshmallow, typing-inspect, openapi-schema-pydantic, marshmallow-enum, langchainplus-sdk, dataclasses-json, langchain\n","Successfully installed dataclasses-json-0.5.8 langchain-0.0.209 langchainplus-sdk-0.0.16 marshmallow-3.19.0 marshmallow-enum-1.5.1 mypy-extensions-1.0.0 openapi-schema-pydantic-1.2.4 typing-inspect-0.9.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting python-dotenv\n","  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n","Installing collected packages: python-dotenv\n","Successfully installed python-dotenv-1.0.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (8.2.2)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting google-search-results\n","  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from google-search-results) (2.27.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.4)\n","Building wheels for collected packages: google-search-results\n","  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32002 sha256=6fcc96c281bfb4c014c4f368447aeb657cde791367820b83cf790eda14bd1b4b\n","  Stored in directory: /root/.cache/pip/wheels/d3/b2/c3/03302d12bb44a2cdff3c9371f31b72c0c4e84b8d2285eeac53\n","Successfully built google-search-results\n","Installing collected packages: google-search-results\n","Successfully installed google-search-results-2.4.2\n"]}],"source":["!pip install openai\n","!pip install langchain\n","!pip install python-dotenv\n","!pip install tenacity\n","!pip install google-search-results"]},{"cell_type":"markdown","source":["# ChatGPT... why API?"],"metadata":{"id":"rX5me_0srqW-"}},{"cell_type":"markdown","source":["1. no public model (openAI가 모델을 여러 이유로 공개하지 않음.)\n","2. too large to run on local (100 trillion parameters, 모델이 하나의 디바이스에서 실행시키기 어려울 정도로 크다.)\n","    \n","\n","그래서 제공되는 API를 활용해서 사용해보자!\n","\n","=> Let's try this model with API!\n"],"metadata":{"id":"170mUd_trsAp"}},{"cell_type":"markdown","source":["# Lets try ChatGPT"],"metadata":{"id":"j40jl2aVPFWJ"}},{"cell_type":"markdown","source":["## API key 발급 받기!\n","https://platform.openai.com/"],"metadata":{"id":"OjxPnDvrtoOl"}},{"cell_type":"markdown","source":["## Simple usage\n","\n","### Best practices?\n","https://platform.openai.com/docs/guides/gpt-best-practices"],"metadata":{"id":"R3LiiytitgHs"}},{"cell_type":"code","source":["import openai\n","api_key = \"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\"\n","openai.api_key = api_key\n","\n","my_prompt =\"What could be a research topic for the combination of LLM and information retrieval?\"\n","# my_prompt =\"Tell me about color green\"\n","prompt = [\n","    {\n","        \"role\": \"user\",\n","        \"content\": my_prompt\n","    }\n","]\n","\n","# https://platform.openai.com/docs/api-reference/completions\n","response = openai.ChatCompletion.create(\n","    model=\"gpt-3.5-turbo\", # https://platform.openai.com/docs/models\n","    messages=prompt,\n","    max_tokens=200,\n","    temperature=1.0,\n","    top_p=1.0,\n","    stop=[\"stop\"],\n","    request_timeout=5,\n",")\n","response"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a4p_Rrwws7xe","executionInfo":{"status":"ok","timestamp":1687487963064,"user_tz":-540,"elapsed":1760,"user":{"displayName":"백삼기","userId":"07015587273030351036"}},"outputId":"1d669255-90ef-4d85-d775-de94baa1e707"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<OpenAIObject chat.completion id=chatcmpl-7UQzhzwZ4Wrw0m4F3wR7yG7vbRlY0 at 0x7fe9ac5883b0> JSON: {\n","  \"id\": \"chatcmpl-7UQzhzwZ4Wrw0m4F3wR7yG7vbRlY0\",\n","  \"object\": \"chat.completion\",\n","  \"created\": 1687487961,\n","  \"model\": \"gpt-3.5-turbo-0301\",\n","  \"choices\": [\n","    {\n","      \"index\": 0,\n","      \"message\": {\n","        \"role\": \"assistant\",\n","        \"content\": \"An analysis of the legal implications and ethical considerations of using artificial intelligence in the legal information retrieval process for LLM programs.\"\n","      },\n","      \"finish_reason\": \"stop\"\n","    }\n","  ],\n","  \"usage\": {\n","    \"prompt_tokens\": 24,\n","    \"completion_tokens\": 24,\n","    \"total_tokens\": 48\n","  }\n","}"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["response[\"choices\"][0][\"message\"][\"content\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"sJr9wFsuqQ6q","executionInfo":{"status":"ok","timestamp":1687487552673,"user_tz":-540,"elapsed":972,"user":{"displayName":"백삼기","userId":"07015587273030351036"}},"outputId":"15a8aee0-6dc3-4c94-9f80-6b576bec327e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\"How can advanced information retrieval technologies be leveraged to facilitate research in LLM program?\"'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["prompt.append({\n","    \"role\": \"assistant\",\n","    \"content\": response[\"choices\"][0][\"message\"][\"content\"]\n","})\n","\n","prompt.append({\n","    \"role\": \"user\",\n","    \"content\": \"Can you give me three other topics as well?\"\n","})\n","\n","# https://platform.openai.com/docs/api-reference/completions\n","response = openai.ChatCompletion.create(\n","    model=\"gpt-3.5-turbo\", # https://platform.openai.com/docs/models\n","    messages=prompt,\n","    max_tokens=200,\n","    temperature=1.0,\n","    top_p=1.0,\n","    stop=[\"stop\"],\n","    request_timeout=5,\n",")"],"metadata":{"id":"T8CVpN_7sVrF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["response"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z4W1tEOIsr-Q","executionInfo":{"status":"ok","timestamp":1687487586080,"user_tz":-540,"elapsed":463,"user":{"displayName":"백삼기","userId":"07015587273030351036"}},"outputId":"1d979796-5a8f-4215-b6f1-ad560ecc18c7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<OpenAIObject chat.completion id=chatcmpl-7UQtXRc5nQm5dpnIt3q23cVMMerON at 0x7fe9c06c5cb0> JSON: {\n","  \"id\": \"chatcmpl-7UQtXRc5nQm5dpnIt3q23cVMMerON\",\n","  \"object\": \"chat.completion\",\n","  \"created\": 1687487579,\n","  \"model\": \"gpt-3.5-turbo-0301\",\n","  \"choices\": [\n","    {\n","      \"index\": 0,\n","      \"message\": {\n","        \"role\": \"assistant\",\n","        \"content\": \"Sure, here are three additional topics for the combination of LLM and information retrieval:\\n\\n1. \\\"Analyzing the effectiveness of different information retrieval methods for LLM research: A comparative study\\\"\\n2. \\\"Exploring the impact of artificial intelligence (AI) and machine learning (ML) on information retrieval in the context of LLM education\\\"\\n3. \\\"Investigating the role of social media platforms in shaping legal discourse and its implications in LLM research and practice\\\"\"\n","      },\n","      \"finish_reason\": \"stop\"\n","    }\n","  ],\n","  \"usage\": {\n","    \"prompt_tokens\": 61,\n","    \"completion_tokens\": 94,\n","    \"total_tokens\": 155\n","  }\n","}"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["from pprint import pprint\n","pprint(response[\"choices\"][0][\"message\"][\"content\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GxEbxt51svgb","executionInfo":{"status":"ok","timestamp":1687488170956,"user_tz":-540,"elapsed":3,"user":{"displayName":"백삼기","userId":"07015587273030351036"}},"outputId":"8f8ba90c-28c0-4741-a737-4e864906fd5b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["('To count the keystrokes needed to type the numbers from 1 to 500, we need to '\n"," 'consider the number of digits in each number.\\n'\n"," '\\n'\n"," 'There are:\\n'\n"," '\\n'\n"," '- 9 one-digit numbers (from 1 to 9) which each require one keystroke.\\n'\n"," '- 90 two-digit numbers (from 10 to 99) which each require two keystrokes.\\n'\n"," '- 401 three-digit numbers (from 100 to 500) which each require three '\n"," 'keystrokes.\\n'\n"," '\\n'\n"," 'Therefore, the total number of keystrokes needed is:\\n'\n"," '\\n'\n"," '9 x 1 + 90 x 2 + 401 x 3 = 9 + 180 + 1203 = 1392\\n'\n"," '\\n'\n"," 'Hence, it takes 1392 keystrokes to type the numbers from 1 to 500.')\n"]}]},{"cell_type":"markdown","source":["## Chain of Thought?\n","LLM 한번에 복잡한 작업을 하기 어려워 함.\n","\n","사고의 과정을 나눠서 알려주면 잘 수행할까?\n","\n","https://arxiv.org/abs/2201.11903"],"metadata":{"id":"14_O8RdP37t3"}},{"cell_type":"code","source":["conversation = []\n","\n","cot_difficult_prompt = \"How many keystrokes are needed to type the numbers from 1 to 500?\" # answer: 1392 = 9 + 90*2 + 400*3 + 3\n","conversation.append({\n","    \"role\": \"user\",\n","    \"content\": cot_difficult_prompt\n","})\n","\n","\n","# https://platform.openai.com/docs/api-reference/completions\n","response = openai.ChatCompletion.create(\n","    model=\"gpt-3.5-turbo\", # https://platform.openai.com/docs/models\n","    messages=conversation,\n","    max_tokens=200,\n","    temperature=1.0,\n","    top_p=1.0,\n","    stop=[\"stop\"],\n","    request_timeout=10,\n",")\n","pprint(response[\"choices\"][0][\"message\"][\"content\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dIPCcum737Si","executionInfo":{"status":"ok","timestamp":1687488182896,"user_tz":-540,"elapsed":6763,"user":{"displayName":"백삼기","userId":"07015587273030351036"}},"outputId":"c830bf40-d2cd-4623-8916-b5a6b034fc8a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["('There are a couple of ways to approach this problem, but one common method '\n"," 'is to count the number of keystrokes needed for each digit and then add them '\n"," 'up for all the numbers.\\n'\n"," '\\n'\n"," 'To type a single-digit number (1 to 9), we need one keystroke. There are 9 '\n"," 'such numbers, so they require 9 keystrokes in total.\\n'\n"," '\\n'\n"," 'To type a two-digit number (10 to 99), we need two keystrokes: one for the '\n"," 'tens digit and one for the ones digit. There are 90 such numbers (10 to 19, '\n"," '20 to 29, etc.), so they require 180 keystrokes in total.\\n'\n"," '\\n'\n"," 'To type a three-digit number (100 to 500), we need three keystrokes: one for '\n"," 'the hundreds digit, one for the tens digit, and one for the ones digit. '\n"," 'There are 4 such numbers (100, 200, 300, 400) that require 3 keystrokes, and '\n"," '100 such numbers (')\n"]}]},{"cell_type":"markdown","source":["Zeroshot CoT"],"metadata":{"id":"cOhjTVSb5WVj"}},{"cell_type":"code","source":["conversation = []\n","\n","cot_difficult_prompt = \"How many keystrokes are needed to type the numbers from 1 to 500?\"\n","conversation.append({\n","    \"role\": \"user\",\n","    \"content\": cot_difficult_prompt\n","})\n","conversation.append({\n","    \"role\": \"user\",\n","    \"content\": \"Lets think step by step\"\n","})\n","\n","# https://platform.openai.com/docs/api-reference/completions\n","response = openai.ChatCompletion.create(\n","    model=\"gpt-3.5-turbo\", # https://platform.openai.com/docs/models\n","    messages=conversation,\n","    max_tokens=200,\n","    temperature=1.0,\n","    top_p=1.0,\n","    stop=[\"stop\"],\n","    request_timeout=10,\n",")\n","pprint(response[\"choices\"][0][\"message\"][\"content\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5AETQA4y4W7D","executionInfo":{"status":"ok","timestamp":1687488198921,"user_tz":-540,"elapsed":6181,"user":{"displayName":"백삼기","userId":"07015587273030351036"}},"outputId":"1505a5db-7b5a-44e4-e01b-572aa8c96a8d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(\"Sure, let's break it down. \\n\"\n"," '\\n'\n"," 'To type the numbers from 1 to 9, we need 9 keystrokes (from 1 to 9).\\n'\n"," '\\n'\n"," 'To type the numbers from 10 to 99, we need 180 keystrokes (10-19 require 10 '\n"," 'keystrokes each, and 20-99 require 9 keystrokes each).\\n'\n"," '\\n'\n"," 'To type the numbers from 100 to 500, we first type \"1\" and \"00\" separately, '\n"," 'which takes 3 keystrokes. Then we need to add the number of keystrokes to '\n"," 'type the numbers from 1 to 400, which is the same as the number of '\n"," 'keystrokes to type the numbers from 1 to 99 (180). Finally, we need to add '\n"," 'the number of keystrokes to type \"01\", \"02\", \"03\", ..., \"99\", which is 180 '\n"," '(because each of those numbers has two digits).\\n'\n"," '\\n'\n"," 'Therefore, the total number of keystrokes needed to type the')\n"]}]},{"cell_type":"markdown","source":["Fewshot CoT"],"metadata":{"id":"iMIeMBgO5VFE"}},{"cell_type":"code","source":["conversation = []\n","\n","conversation.append({\n","    \"role\": \"user\",\n","    \"content\": \"I will give you an example answer of the question\\n\"\n","               \"Example Q: How many keystrokes are needed to type the numbers from 1 to 22?\\n\"\n","               \"Example A: To type from 1 to 9, 9 keystrokes are needed. To type from 10 to 22, we need 13 x 2 = 26 keystrokes. Therefore, in total 9 + 26 = 35 keystrokes are needed.\"\n","})\n","conversation.append({\n","    \"role\": \"user\",\n","    \"content\": \"Q: How many keystrokes are needed to type the numbers from 1 to 500?\"\n","})\n","\n","conversation.append({\n","    \"role\": \"user\",\n","    \"content\": \"Now Lets think step by step\"\n","})\n","\n","# https://platform.openai.com/docs/api-reference/completions\n","response = openai.ChatCompletion.create(\n","    model=\"gpt-3.5-turbo\", # https://platform.openai.com/docs/models\n","    messages=conversation,\n","    max_tokens=200,\n","    temperature=1.0,\n","    top_p=1.0,\n","    stop=[\"stop\"],\n","    request_timeout=10,\n",")\n","pprint(response[\"choices\"][0][\"message\"][\"content\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AH7DqOcV5a6H","executionInfo":{"status":"ok","timestamp":1687488347972,"user_tz":-540,"elapsed":7414,"user":{"displayName":"백삼기","userId":"07015587273030351036"}},"outputId":"320e1f3b-a57b-491b-f13b-be0869fe8b73"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(\"Sure, let's break it down step by step.\\n\"\n"," '\\n'\n"," 'First, we need to think about how many keystrokes are needed to type the '\n"," 'numbers from 1 to 9. There are nine single-digit numbers, so we can type '\n"," 'them with nine keystrokes.\\n'\n"," '\\n'\n"," 'Next, we need to consider the two-digit numbers between 10 and 99. Each of '\n"," 'these numbers has two digits, so we need two keystrokes to type them. There '\n"," 'are 90 two-digit numbers between 10 and 99, so we need 90 x 2 = 180 '\n"," 'keystrokes to type these numbers.\\n'\n"," '\\n'\n"," 'Now we need to think about the three-digit numbers between 100 and 500. Each '\n"," 'of these numbers has three digits, so we need three keystrokes to type them. '\n"," 'There are 400 three-digit numbers between 100 and 500, so we need 400 x 3 = '\n"," '1200 keystrokes to type these numbers.\\n'\n"," '\\n'\n"," 'Therefore, to type the numbers from 1 to 500,')\n"]}]},{"cell_type":"code","source":["!pip install bardapi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YLe4sVwVNOpl","executionInfo":{"status":"ok","timestamp":1687489463469,"user_tz":-540,"elapsed":4835,"user":{"displayName":"백삼기","userId":"07015587273030351036"}},"outputId":"5778baeb-4630-40bc-faae-4d729b065676"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting bardapi\n","  Downloading bardapi-0.1.11-py3-none-any.whl (8.8 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bardapi) (2.27.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bardapi) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bardapi) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->bardapi) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bardapi) (3.4)\n","Installing collected packages: bardapi\n","Successfully installed bardapi-0.1.11\n"]}]},{"cell_type":"code","source":["from bardapi import Bard\n","\n","token = 'YAhl7rQhUzhmmN7i0do0-_7NYGAB1Ke7ClaOp3RSJ94Wxtn62ItG6o3O226DEiIJM8uKyg.'\n","bard = Bard(token=token)\n","bard.get_answer(\"tell me about Newjeans\")['content']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"id":"YO-v90NlNdGz","executionInfo":{"status":"ok","timestamp":1687489827063,"user_tz":-540,"elapsed":492,"user":{"displayName":"백삼기","userId":"07015587273030351036"}},"outputId":"f73f3fb2-2be6-4bd5-c082-2467c5bbb62e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Response Error: b\\')]}\\\\\\'\\\\n\\\\n38\\\\n[[\"wrb.fr\",null,null,null,null,[9]]]\\\\n55\\\\n[[\"di\",66],[\"af.httprm\",66,\"-4035731694265189369\",2]]\\\\n25\\\\n[[\"e\",4,null,null,130]]\\\\n\\'.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["# Let's try LangChain"],"metadata":{"id":"Qt02BwLJrkdr"}},{"cell_type":"markdown","source":["### Simple Example"],"metadata":{"id":"DAYsegAzvUWF"}},{"cell_type":"code","source":["from langchain.llms import OpenAI\n","api_key = \"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\"\n","llm = OpenAI(\n","    # model_name=\"gpt-3.5-turbo\",\n","    openai_api_key=api_key,\n","    temperature=0.9\n","    )"],"metadata":{"id":"_wI2MbjPrmjV","executionInfo":{"status":"ok","timestamp":1687502789395,"user_tz":-540,"elapsed":2098,"user":{"displayName":"백삼기","userId":"07015587273030351036"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["llm.predict(\"What would be a good company name for a company that makes colorful socks?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"hKKY3He0u33W","executionInfo":{"status":"ok","timestamp":1687502797237,"user_tz":-540,"elapsed":1537,"user":{"displayName":"백삼기","userId":"07015587273030351036"}},"outputId":"e7bf5559-1455-4ba5-c3b0-c842bc07d6e5"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n\\nJoyful Socks.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["### Chat Example"],"metadata":{"id":"pB9WfW8mvWQ9"}},{"cell_type":"code","source":["from langchain.chat_models import ChatOpenAI\n","from langchain.schema import (\n","    AIMessage,\n","    HumanMessage,\n","    SystemMessage\n",")\n","\n","chat = ChatOpenAI(\n","    model_name=\"gpt-3.5-turbo\",\n","    openai_api_key=api_key,\n","    temperature=0\n",")\n","chat.predict_messages(\n","    [HumanMessage(content=\"Translate this sentence from English to French. I love programming.\")]\n",")\n","# >> AIMessage(content=\"J'aime programmer.\", additional_kwargs={})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nrp7y26Fu64m","executionInfo":{"status":"ok","timestamp":1687502811858,"user_tz":-540,"elapsed":1417,"user":{"displayName":"백삼기","userId":"07015587273030351036"}},"outputId":"91a3a9ba-1ed7-4d14-81a9-92e3b42f659c"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content=\"J'aime programmer.\", additional_kwargs={}, example=False)"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["chat.predict(\"Translate this sentence from English to French. I love programming.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"o6X4l36ivBVc","executionInfo":{"status":"ok","timestamp":1687502815090,"user_tz":-540,"elapsed":1155,"user":{"displayName":"백삼기","userId":"07015587273030351036"}},"outputId":"571d3621-6ef2-49e1-d35a-c292c9f6b112"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"J'aime programmer.\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["### Prompt template"],"metadata":{"id":"j0BBUyzAvYC7"}},{"cell_type":"code","source":["# for prodtype in prodtypes:\n","#   llmsuggestion = LLM(prodtype)"],"metadata":{"id":"v4mL48djA2wn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain.prompts import PromptTemplate\n","\n","prompt = PromptTemplate.from_template(\"What is a good name for a company that makes {product}?\")\n","print(prompt.format(product=\"colorful socks\"))\n","print(prompt.format(product=\"AI products\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bLIr6gwGvKFx","executionInfo":{"status":"ok","timestamp":1687502978747,"user_tz":-540,"elapsed":675,"user":{"displayName":"백삼기","userId":"07015587273030351036"}},"outputId":"ac7afba1-7e87-4316-84f0-97e80299de2c"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["What is a good name for a company that makes colorful socks?\n","What is a good name for a company that makes AI products?\n"]}]},{"cell_type":"code","source":["from langchain.prompts import PromptTemplate\n","\n","prompt = PromptTemplate.from_template(\"Give me a three-sentence slogan for a product, that rhymes. The product is {product}?\")\n","print(prompt.format(product=\"colorful socks\"))\n","print(prompt.format(product=\"electric bicycle\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9JXPDkqZBAXQ","executionInfo":{"status":"ok","timestamp":1687503159997,"user_tz":-540,"elapsed":395,"user":{"displayName":"백삼기","userId":"07015587273030351036"}},"outputId":"b03024f3-5542-4e93-d150-76548f58af67"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Give me a three-sentence slogan for a product, that rhymes. The product is colorful socks?\n","Give me a three-sentence slogan for a product, that rhymes. The product is electric bicycle?\n"]}]},{"cell_type":"code","source":["prompt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wux37di0BxOY","executionInfo":{"status":"ok","timestamp":1687503185068,"user_tz":-540,"elapsed":2,"user":{"displayName":"백삼기","userId":"07015587273030351036"}},"outputId":"11ac974e-3fa3-47ce-c666-6fc6944ed571"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PromptTemplate(input_variables=['product'], output_parser=None, partial_variables={}, template='Give me a three-sentence slogan for a product, that rhymes. The product is {product}?', template_format='f-string', validate_template=True)"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["## Chain"],"metadata":{"id":"fK8bRYdMvlT6"}},{"cell_type":"code","source":["from langchain.chains import LLMChain\n","\n","chain = LLMChain(llm=llm, prompt=prompt)\n","chain.run(\"colorful socks\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"YHFeHy3-vaxx","executionInfo":{"status":"ok","timestamp":1687503222560,"user_tz":-540,"elapsed":1700,"user":{"displayName":"백삼기","userId":"07015587273030351036"}},"outputId":"b1bf038d-db38-4480-8b5d-c68bf66cb5bb"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n\\nSocks that are bold and bright,\\nAn array of colors that take flight,\\nCome get some quick and make it right!'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["chain.run(\"american pizza\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Nx4zwrOWCK64","executionInfo":{"status":"ok","timestamp":1687503297952,"user_tz":-540,"elapsed":1510,"user":{"displayName":"백삼기","userId":"07015587273030351036"}},"outputId":"fbfc62ac-366f-45b3-be3e-10cfd3c53939"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n\\nTaste the best in the west,\\nForget the rest and come confess,\\nAmerican pizza will be your success!'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["## Search Agent"],"metadata":{"id":"o-02Qo6fvsEh"}},{"cell_type":"markdown","source":["### SERPAPI key!\n","https://serpapi.com/"],"metadata":{"id":"qpSPavpPxB2v"}},{"cell_type":"code","source":["from langchain.agents import AgentType, initialize_agent, load_tools\n","from langchain.llms import OpenAI\n","\n","# https://serpapi.com/\n","# serp_api_key = ...\n","serp_api_key = \"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\"\n","\n","# The language model we're going to use to control the agent.\n","llm = OpenAI(\n","    openai_api_key=api_key,\n","    temperature=0\n",")\n","\n","# The tools we'll give the Agent access to. Note that the 'llm-math' tool uses an LLM, so we need to pass that in.\n","tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm, serpapi_api_key=serp_api_key)\n","\n","# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n","agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n","\n","# Let's test it out!\n","agent.run(\"What was the high temperature in SF yesterday in Fahrenheit? What is that number raised to the .023 power?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":469},"id":"VQlQbjQPvm-s","executionInfo":{"status":"error","timestamp":1687503645476,"user_tz":-540,"elapsed":2577,"user":{"displayName":"백삼기","userId":"07015587273030351036"}},"outputId":"e6fcbeeb-35bd-4e1e-c93f-da2466e7d34b"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new  chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3m I need to find the temperature first, then use the calculator to raise it to the .023 power.\n","Action: Search\n","Action Input: \"High temperature in SF yesterday\"\u001b[0m"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-371db1ae9ac7>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Let's test it out!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What was the high temperature in SF yesterday in Fahrenheit? What is that number raised to the .023 power?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, callbacks, tags, *args, **kwargs)\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`run` supports only one positional argument.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_output_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, include_run_info)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         final_outputs: Dict[str, Any] = self.prep_outputs(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, include_run_info)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             outputs = (\n\u001b[0;32m--> 160\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    955\u001b[0m         \u001b[0;31m# We now enter the agent loop (until it returns something).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_continue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_elapsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 957\u001b[0;31m             next_step_output = self._take_next_step(\n\u001b[0m\u001b[1;32m    958\u001b[0m                 \u001b[0mname_to_tool_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                 \u001b[0mcolor_mapping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    818\u001b[0m                     \u001b[0mtool_run_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"llm_prefix\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m                 \u001b[0;31m# We then call the tool on the tool input to get an observation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                 observation = tool.run(\n\u001b[0m\u001b[1;32m    821\u001b[0m                     \u001b[0magent_action\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtool_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/tools/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_tool_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m             run_manager.on_tool_end(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/tools/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0mtool_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtool_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_args_and_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             observation = (\n\u001b[0;32m--> 269\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtool_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtool_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtool_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtool_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/tools/base.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, run_manager, *args, **kwargs)\u001b[0m\n\u001b[1;32m    416\u001b[0m             )\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnew_argument_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m             \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m         )\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/utilities/serpapi.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, query, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;34m\"\"\"Run query through SerpAPI and parse result.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/utilities/serpapi.py\u001b[0m in \u001b[0;36m_process_response\u001b[0;34m(res)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;34m\"\"\"Process response from SerpAPI.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Got error from SerpAPI: {res['error']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"answer_box\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"answer_box\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"answer_box\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"answer_box\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Got error from SerpAPI: Invalid API key. Your API key should be here: https://serpapi.com/manage-api-key"]}]},{"cell_type":"markdown","source":["### Other useful predefined tools?\n","https://python.langchain.com/docs/modules/agents/tools/"],"metadata":{"id":"OCOwTuATzgKI"}},{"cell_type":"markdown","source":["## Memory"],"metadata":{"id":"O5z5_qtPv2H6"}},{"cell_type":"code","source":["from langchain import OpenAI, ConversationChain\n","\n","llm = OpenAI(\n","    openai_api_key=api_key,\n","    temperature=0\n",")\n","conversation = ConversationChain(llm=llm, verbose=True)\n","\n","conversation.run(\"Hi there!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":270},"id":"LiMDntesv1hi","executionInfo":{"status":"ok","timestamp":1687448212273,"user_tz":-540,"elapsed":1431,"user":{"displayName":"Jongyoon Kim","userId":"08712802308506339754"}},"outputId":"fea47971-d0de-4a5d-d97b-efa18286b889"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new  chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","\n","Human: Hi there!\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["\" Hi there! It's nice to meet you. How can I help you today?\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["conversation.run(\"I'm doing well! Just having a conversation with an AI.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":288},"id":"u6Nq2OzkwEk9","executionInfo":{"status":"ok","timestamp":1687448244320,"user_tz":-540,"elapsed":2087,"user":{"displayName":"Jongyoon Kim","userId":"08712802308506339754"}},"outputId":"0f836cc2-cdbe-4d19-bb95-d9097345acbf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new  chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","Human: Hi there!\n","AI:  Hi there! It's nice to meet you. How can I help you today?\n","Human: I'm doing well! Just having a conversation with an AI.\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["\" That's great! It's always nice to have a conversation with someone new. What would you like to talk about?\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["## Use Cases\n","https://python.langchain.com/docs/use_cases"],"metadata":{"id":"olZPrchurBZM"}},{"cell_type":"code","source":[],"metadata":{"id":"Nra7C0fGwMT6"},"execution_count":null,"outputs":[]}]}