{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "PyTorch 1.0.0-3.6",
      "language": "python",
      "name": "multitask"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ec1NCtLafD2"
      },
      "source": [
        "# 1. Preparations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchdata\n",
        "!pip install portalocker>=2.0.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ji_jKrXN7hf6",
        "outputId": "74499b6f-eab6-4377-c499-28c0be340ac0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchdata in /usr/local/lib/python3.10/dist-packages (0.6.1)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata) (1.26.16)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.27.1)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchdata) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchdata) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchdata) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchdata) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchdata) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchdata) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchdata) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchdata) (16.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->torchdata) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->torchdata) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFpwJWt6H8i-"
      },
      "source": [
        "### 1-1. Import Libraries\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuWiZzTJIHlX"
      },
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "import sys\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchtext import data, datasets\n",
        "import time\n",
        "import spacy\n",
        "import numpy as np\n",
        "from torch import Tensor\n",
        "from torchtext.datasets import IMDB"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3G5gZ-VWw8s3",
        "outputId": "62dc9fb8-c964-4a52-d52c-3cfdc22623ca"
      },
      "source": [
        "import torchtext\n",
        "torchtext.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.15.2+cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlBRh_erIV5Y"
      },
      "source": [
        "### 1-2. Load data\n",
        "- IMDB 데이터를 다운받습니다.\n",
        "- Train,valid,test 데이터셋으로 split 합니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install datasets"
      ],
      "metadata": {
        "id": "vSiI-eyn6NU5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from datasets import load_dataset\n",
        "# imdb=load_dataset(\"imdb\")"
      ],
      "metadata": {
        "id": "MxJQR9Ht6AFm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.datasets import IMDB\n",
        "train_iter, test_iter = IMDB(split=('train', 'test'))"
      ],
      "metadata": {
        "id": "f3Jv2J-77azH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "*   split train data into 7:3 portion as train:valid\n",
        "\n"
      ],
      "metadata": {
        "id": "94FxUKYFkrOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "length = len(list(train_iter))\n",
        "print(length)\n",
        "valid_iter = list(train_iter)[int(0.7*length):]\n",
        "train_iter = list(train_iter)[:int(0.7*length)]"
      ],
      "metadata": {
        "id": "q6I1lixaki0J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96df270a-dfd6-4f16-c415-8a6188b7ceb9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(list(train_iter)))\n",
        "print(len(list(valid_iter)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TklZkkmmzDpK",
        "outputId": "caec38da-55ab-4f38-b9c9-0de7b73cc9a8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17500\n",
            "7500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "TioP4O6C672Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1-3. Building Vocabulary\n",
        "\n",
        "\n",
        "*   Build the vocabulary directly with the Vocab class\n",
        "\n"
      ],
      "metadata": {
        "id": "WgPFTSsvfuGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "tokenizer = get_tokenizer('basic_english')"
      ],
      "metadata": {
        "id": "5T4hGt6Y9B1f"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from torchtext.vocab import vocab\n",
        "from torchtext.datasets import IMDB\n",
        "#train_iter = IMDB(split='train')\n",
        "counter = Counter()\n",
        "#for (label, line) in imdb['train']:\n",
        "for (label, line) in train_iter:\n",
        "    counter.update(tokenizer(line))\n",
        "vocab = vocab(counter, min_freq=1, specials=('<unk>', '<BOS>', '<EOS>', '<PAD>'))\n",
        "vocab.set_default_index(vocab['<unk>'])\n"
      ],
      "metadata": {
        "id": "E6r7QfGt9zwG"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The length of the new vocab is\", len(vocab))\n",
        "new_stoi = vocab.get_stoi()\n",
        "print(\"The index of '<BOS>' is\", new_stoi['<BOS>'])\n",
        "new_itos = vocab.get_itos()\n",
        "print(\"The token at index 2 is\", new_itos[2])\n",
        "print(\"The token at index 3 is\", new_itos[3])\n",
        "print(\"The token at index 100 is\", new_itos[100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5s2oNweoAG2G",
        "outputId": "9d08d693-13df-4772-c091-cfa81b01e358"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of the new vocab is 100686\n",
            "The index of '<BOS>' is 1\n",
            "The token at index 2 is <EOS>\n",
            "The token at index 3 is <PAD>\n",
            "The token at index 100 is ordinary\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "*   Build Vocabulary using GloVe\n",
        "(3분 정도 소요)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2rOkBBn-hJ7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from torchtext.vocab import GloVe, vocab\n",
        "\n",
        "#glove_vectors = GloVe(name='6B', dim=100)\n",
        "#glove_vocab = vocab(glove_vectors.stoi)\n",
        "#vocab_byname = glove_vocab.get_stoi()\n",
        "#vocab_byindex = glove_vocab.get_itos()"
      ],
      "metadata": {
        "id": "J5R5qG-bQwxu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\"'.format(name=fn))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "id": "doNd0SxvTBYt",
        "outputId": "3b375eaa-0597-450d-edec-785db4625506"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-083837b4-d2c8-4f59-9a97-a95e7fab0f85\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-083837b4-d2c8-4f59-9a97-a95e7fab0f85\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving glove.6B.100d.zip to glove.6B.100d.zip\n",
            "User uploaded file \"glove.6B.100d.zip\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq \"./glove.6B.100d.zip\""
      ],
      "metadata": {
        "id": "i9wX2op-cc9j"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.vocab import vocab, Vectors\n",
        "\n",
        "class GloVe(Vectors):\n",
        "    url = {\n",
        "        \"42B\": \"http://nlp.stanford.edu/data/glove.42B.300d.zip\",\n",
        "        \"840B\": \"http://nlp.stanford.edu/data/glove.840B.300d.zip\",\n",
        "        \"twitter.27B\": \"http://nlp.stanford.edu/data/glove.twitter.27B.zip\",\n",
        "        \"6B\": \"/content/glove.6B.100d.zip\",\n",
        "    }\n",
        "    def __init__(self, name=\"840B\", dim=300, **kwargs) -> None:\n",
        "        url = self.url[name]\n",
        "        name = \"glove.{}.{}d.txt\".format(name, str(dim))\n",
        "        super(GloVe, self).__init__(name, url=url, **kwargs)\n"
      ],
      "metadata": {
        "id": "DOoWZvgQSFBk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove_vectors = GloVe(name='6B', dim=100)"
      ],
      "metadata": {
        "id": "Xperbavuc3JQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "153814a2-59c1-4a4f-b9cf-b46bc5145c1d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████▉| 400000/400001 [00:22<00:00, 17945.72it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unk_index = 0\n",
        "bos_index = 1\n",
        "eos_index = 2\n",
        "pad_index = 3\n",
        "glove_vectors = GloVe(name='6B', dim=100)\n",
        "glove_vocab = vocab(glove_vectors.stoi)\n",
        "glove_vocab.insert_token(\"<UNK>\",unk_index)\n",
        "glove_vocab.insert_token(\"<BOS>\",bos_index)\n",
        "glove_vocab.insert_token(\"<EOS>\",eos_index)\n",
        "glove_vocab.insert_token(\"<PAD>\",pad_index)\n",
        "vocab_byname = glove_vocab.get_stoi()\n",
        "vocab_byindex = glove_vocab.get_itos()\n",
        "\n",
        "pretrained_embeddings = glove_vectors.vectors\n",
        "pretrained_embeddings = torch.cat((torch.zeros(4,pretrained_embeddings.shape[1]),pretrained_embeddings))\n",
        "\n",
        "glove_vocab.set_default_index(unk_index)\n",
        "\n",
        "vocab = glove_vocab.get_stoi()"
      ],
      "metadata": {
        "id": "FDGZbVxsoZFe"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The length of the new vocab is\", len(pretrained_embeddings))\n",
        "new_stoi = glove_vocab.get_stoi()\n",
        "print(\"The index of '<UNK>' is\", new_stoi['<UNK>'])\n",
        "new_itos = glove_vocab.get_itos()\n",
        "print(\"The token at index 2 is\", new_itos[2])\n",
        "print(\"The token at index 2100 is\", new_itos[2100])\n",
        "print(\"The token at index 210000 is\", new_itos[78634])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsIqF2TSRANR",
        "outputId": "bbccc675-56f6-4674-adcd-0454544f61cf"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of the new vocab is 400005\n",
            "The index of '<UNK>' is 0\n",
            "The token at index 2 is <EOS>\n",
            "The token at index 2100 is stood\n",
            "The token at index 210000 is canisius\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(glove_vectors.vectors[-1])\n",
        "print(glove_vectors.vectors[100])\n",
        "print(glove_vectors.vectors[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAOyGvVLwday",
        "outputId": "5422a91f-b163-4904-e5b0-43fbe790cbc8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.2837, -0.6263, -0.4435,  0.2177, -0.0874, -0.1706,  0.2927, -0.0249,\n",
            "         0.2641, -0.1702,  0.2582,  0.0975, -0.3310, -0.4386,  0.0096,  0.0956,\n",
            "        -0.1778,  0.3889,  0.2715,  0.1474, -0.4397, -0.2659, -0.0243,  0.2719,\n",
            "        -0.3676, -0.2483, -0.2081,  0.2213, -0.0444,  0.0214,  0.2459,  0.2614,\n",
            "         0.2930,  0.1328,  0.0822, -0.1287,  0.1622, -0.2257, -0.0603,  0.2870,\n",
            "         0.1138,  0.3484,  0.3419,  0.3700, -0.1359,  0.0063,  0.0803,  0.0036,\n",
            "         0.4309,  0.0188,  0.3101,  0.1672,  0.0741, -0.3774,  0.4736,  0.4128,\n",
            "         0.2447,  0.0760, -0.5173, -0.4948,  0.5260, -0.0746,  0.4143, -0.1956,\n",
            "        -0.1654, -0.0456, -0.4015, -0.1314, -0.4672,  0.1883,  0.2612,  0.1685,\n",
            "         0.2262,  0.6299, -0.1288,  0.0558,  0.0193,  0.0246,  0.4688,  0.2582,\n",
            "        -0.3167,  0.0486,  0.3277, -0.5014,  0.3086,  0.1200, -0.2577, -0.0399,\n",
            "        -0.0597,  0.5525,  0.1389, -0.2286,  0.0718, -0.4321,  0.5398, -0.0858,\n",
            "         0.0327,  0.4368, -0.8261, -0.1570])\n",
            "tensor([-3.9551e-01,  5.4660e-01,  5.0315e-01, -6.3682e-01, -4.5470e-01,\n",
            "         3.0889e-01, -4.9240e-02,  2.7191e-01,  3.1562e-01, -3.2879e-01,\n",
            "         2.5089e-01,  1.4508e-01,  3.5136e-01, -2.2793e-01, -1.5894e-01,\n",
            "        -5.1527e-01, -2.7978e-01,  3.6470e-01, -3.9425e-01,  3.3299e-01,\n",
            "         4.3051e-01,  1.8300e-01,  2.5095e-01, -1.8547e-01,  3.4698e-01,\n",
            "         5.5137e-02, -4.5979e-01, -8.2963e-01, -1.8523e-02, -3.6772e-01,\n",
            "         4.5566e-02,  7.1052e-01, -2.2782e-02, -8.0889e-02,  2.0685e-01,\n",
            "         4.9855e-01, -5.9794e-02, -8.0048e-03, -2.3823e-01, -3.3759e-01,\n",
            "        -2.4201e-01, -2.3788e-01, -1.1362e-03, -4.0395e-01, -4.4859e-01,\n",
            "        -3.2189e-01,  4.8405e-01, -2.7999e-02,  1.0148e-01, -9.3585e-01,\n",
            "        -8.7522e-02, -3.9959e-01,  3.6545e-01,  1.3726e+00, -3.0713e-01,\n",
            "        -2.5940e+00,  2.2431e-01, -4.1168e-02,  1.7765e+00,  4.0010e-01,\n",
            "        -1.0996e-01,  1.4178e+00, -2.6154e-01,  1.8617e-01,  7.9328e-01,\n",
            "        -1.1709e-01,  8.7541e-01,  4.3911e-01,  3.4711e-01, -2.8515e-01,\n",
            "         7.6269e-02, -6.3038e-01,  1.6408e-01, -3.7053e-01,  5.8485e-01,\n",
            "        -1.5472e-01, -2.6382e-01, -1.8590e-01, -7.5228e-01, -1.5752e-01,\n",
            "         7.8539e-01, -1.8846e-02, -8.0130e-01,  1.5561e-01, -1.8624e+00,\n",
            "        -1.6969e-01,  1.9419e-01, -3.0683e-01, -7.8067e-01, -4.9689e-01,\n",
            "        -1.8256e-01, -4.2016e-02, -2.6290e-01,  5.8531e-02, -4.4664e-01,\n",
            "        -9.9765e-02, -4.3050e-01, -2.3693e-01, -1.4519e-02,  3.1981e-01])\n",
            "tensor([-0.0382, -0.2449,  0.7281, -0.3996,  0.0832,  0.0440, -0.3914,  0.3344,\n",
            "        -0.5755,  0.0875,  0.2879, -0.0673,  0.3091, -0.2638, -0.1323, -0.2076,\n",
            "         0.3340, -0.3385, -0.3174, -0.4834,  0.1464, -0.3730,  0.3458,  0.0520,\n",
            "         0.4495, -0.4697,  0.0263, -0.5415, -0.1552, -0.1411, -0.0397,  0.2828,\n",
            "         0.1439,  0.2346, -0.3102,  0.0862,  0.2040,  0.5262,  0.1716, -0.0824,\n",
            "        -0.7179, -0.4153,  0.2033, -0.1276,  0.4137,  0.5519,  0.5791, -0.3348,\n",
            "        -0.3656, -0.5486, -0.0629,  0.2658,  0.3020,  0.9977, -0.8048, -3.0243,\n",
            "         0.0125, -0.3694,  2.2167,  0.7220, -0.2498,  0.9214,  0.0345,  0.4674,\n",
            "         1.1079, -0.1936, -0.0746,  0.2335, -0.0521, -0.2204,  0.0572, -0.1581,\n",
            "        -0.3080, -0.4162,  0.3797,  0.1501, -0.5321, -0.2055, -1.2526,  0.0716,\n",
            "         0.7056,  0.4974, -0.4206,  0.2615, -1.5380, -0.3022, -0.0734, -0.2831,\n",
            "         0.3710, -0.2522,  0.0162, -0.0171, -0.3898,  0.8742, -0.7257, -0.5106,\n",
            "        -0.5203, -0.1459,  0.8278,  0.2706])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pretrained_embeddings[-1])\n",
        "print(pretrained_embeddings[103])\n",
        "print(pretrained_embeddings[0])\n",
        "print(pretrained_embeddings[4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qozYVHQyO0V",
        "outputId": "fff85ac0-4a22-4a56-f678-2890805b803e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.2837, -0.6263, -0.4435,  0.2177, -0.0874, -0.1706,  0.2927, -0.0249,\n",
            "         0.2641, -0.1702,  0.2582,  0.0975, -0.3310, -0.4386,  0.0096,  0.0956,\n",
            "        -0.1778,  0.3889,  0.2715,  0.1474, -0.4397, -0.2659, -0.0243,  0.2719,\n",
            "        -0.3676, -0.2483, -0.2081,  0.2213, -0.0444,  0.0214,  0.2459,  0.2614,\n",
            "         0.2930,  0.1328,  0.0822, -0.1287,  0.1622, -0.2257, -0.0603,  0.2870,\n",
            "         0.1138,  0.3484,  0.3419,  0.3700, -0.1359,  0.0063,  0.0803,  0.0036,\n",
            "         0.4309,  0.0188,  0.3101,  0.1672,  0.0741, -0.3774,  0.4736,  0.4128,\n",
            "         0.2447,  0.0760, -0.5173, -0.4948,  0.5260, -0.0746,  0.4143, -0.1956,\n",
            "        -0.1654, -0.0456, -0.4015, -0.1314, -0.4672,  0.1883,  0.2612,  0.1685,\n",
            "         0.2262,  0.6299, -0.1288,  0.0558,  0.0193,  0.0246,  0.4688,  0.2582,\n",
            "        -0.3167,  0.0486,  0.3277, -0.5014,  0.3086,  0.1200, -0.2577, -0.0399,\n",
            "        -0.0597,  0.5525,  0.1389, -0.2286,  0.0718, -0.4321,  0.5398, -0.0858,\n",
            "         0.0327,  0.4368, -0.8261, -0.1570])\n",
            "tensor([ 3.2396e-01,  5.9810e-01,  1.2378e+00,  2.1162e-01,  3.2223e-01,\n",
            "        -9.3300e-01, -3.6429e-01, -4.6309e-01, -1.9794e-01,  1.9983e-01,\n",
            "         1.3876e-01, -5.8763e-01,  9.7240e-02,  2.8784e-01, -1.9291e-01,\n",
            "         2.5512e-01,  3.5596e-01, -4.2983e-01, -7.5188e-01, -1.0966e-01,\n",
            "         1.1040e+00,  2.1188e-01,  7.4477e-01,  4.2071e-01, -1.8735e-01,\n",
            "         2.4202e-01,  4.6133e-01, -1.1325e+00,  4.8860e-01, -2.9384e-02,\n",
            "         3.3875e-01,  5.3299e-01, -2.5313e-01,  1.1577e-01, -8.8380e-02,\n",
            "         6.2731e-01, -1.0941e-01, -1.6472e-01,  3.4720e-01,  5.6492e-01,\n",
            "        -7.4448e-01, -9.9980e-01,  2.2918e-01,  8.5612e-01,  7.5357e-01,\n",
            "        -4.8493e-02, -3.1846e-01, -8.3283e-01, -7.4052e-01, -1.6537e+00,\n",
            "         3.8901e-01, -3.5591e-01,  6.0411e-01,  8.1544e-01, -2.1813e-03,\n",
            "        -2.2976e+00,  6.3694e-02, -9.7151e-01,  2.2791e+00,  4.3913e-01,\n",
            "        -1.1079e-01,  2.7595e-01,  1.0608e+00, -1.2467e-02, -2.4295e-01,\n",
            "        -2.8065e-01, -2.6690e-01,  9.9697e-01,  9.3197e-02,  6.6320e-01,\n",
            "         2.5634e-02, -6.5658e-01, -7.2335e-01, -1.6165e-01,  1.6611e-01,\n",
            "         4.5200e-01,  5.7443e-01,  2.4713e-01, -1.5824e+00,  5.9356e-02,\n",
            "         1.3486e+00, -4.1878e-02, -1.8273e-01,  5.1898e-01, -8.3905e-01,\n",
            "        -3.8870e-01,  4.3774e-01,  9.9288e-02,  2.9579e-01, -1.0994e+00,\n",
            "        -1.0151e-01,  1.8774e-01, -6.5817e-01, -2.3207e-01, -7.4606e-01,\n",
            "         2.4291e-01,  1.2691e-01,  1.0485e-01,  4.9419e-01,  3.0868e-01])\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0.])\n",
            "tensor([-0.0382, -0.2449,  0.7281, -0.3996,  0.0832,  0.0440, -0.3914,  0.3344,\n",
            "        -0.5755,  0.0875,  0.2879, -0.0673,  0.3091, -0.2638, -0.1323, -0.2076,\n",
            "         0.3340, -0.3385, -0.3174, -0.4834,  0.1464, -0.3730,  0.3458,  0.0520,\n",
            "         0.4495, -0.4697,  0.0263, -0.5415, -0.1552, -0.1411, -0.0397,  0.2828,\n",
            "         0.1439,  0.2346, -0.3102,  0.0862,  0.2040,  0.5262,  0.1716, -0.0824,\n",
            "        -0.7179, -0.4153,  0.2033, -0.1276,  0.4137,  0.5519,  0.5791, -0.3348,\n",
            "        -0.3656, -0.5486, -0.0629,  0.2658,  0.3020,  0.9977, -0.8048, -3.0243,\n",
            "         0.0125, -0.3694,  2.2167,  0.7220, -0.2498,  0.9214,  0.0345,  0.4674,\n",
            "         1.1079, -0.1936, -0.0746,  0.2335, -0.0521, -0.2204,  0.0572, -0.1581,\n",
            "        -0.3080, -0.4162,  0.3797,  0.1501, -0.5321, -0.2055, -1.2526,  0.0716,\n",
            "         0.7056,  0.4974, -0.4206,  0.2615, -1.5380, -0.3022, -0.0734, -0.2831,\n",
            "         0.3710, -0.2522,  0.0162, -0.0171, -0.3898,  0.8742, -0.7257, -0.5106,\n",
            "        -0.5203, -0.1459,  0.8278,  0.2706])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_transform = lambda x: [glove_vocab['<BOS>']] + [glove_vocab[token] for token in tokenizer(x)] + [glove_vocab['<EOS>']]\n",
        "label_transform = lambda x: 1 if x == 2 else 0\n",
        "\n",
        "# Print out the output of text_transform\n",
        "print(\"input to the text_transform:\", \"here is an example\")\n",
        "print(\"output of the text_transform:\", text_transform(\"here is an example\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhlvYsA1Drje",
        "outputId": "b4c55795-0add-44fa-eb44-fe87154e37d8"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input to the text_transform: here is an example\n",
            "output of the text_transform: [1, 190, 17, 32, 883, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_transform = lambda x: [vocab['<BOS>']] + [vocab[token] for token in tokenizer(x)] + [vocab['<EOS>']]\n",
        "label_transform = lambda x: 1 if x == 2 else 0\n",
        "\n",
        "# Print out the output of text_transform\n",
        "print(\"input to the text_transform:\", \"here is an example\")\n",
        "print(\"output of the text_transform:\", text_transform(\"here is an example\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0bKemQ8SBvD",
        "outputId": "9397470d-8834-4531-9593-c1277e410198"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input to the text_transform: here is an example\n",
            "output of the text_transform: [1, 1060, 56, 202, 3977, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dDuDBdvsOmk"
      },
      "source": [
        "# Split train and valid data\n",
        "#train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEsf_UifafEH"
      },
      "source": [
        "### 1-3. Cuda Setup\n",
        "- GPU 사용을 위한 Cuda 설정\n",
        "- Colab 페이지 상단 메뉴>수정>노트설정에서 GPU 사용 설정이 선행되어야 합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4BsnajZafEI"
      },
      "source": [
        "USE_CUDA = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if USE_CUDA else \"cpu\")"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "USE_CUDA"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARVtXB7uBdDJ",
        "outputId": "e026ada1-48ed-4f00-b421-70dfa752084c"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8fuDdBOafEO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfd3e165-a617-47f3-f6bc-59b6f6791a3b"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jun 26 01:21:17 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   68C    P0    28W /  70W |  11613MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC9xHrlt4LL9"
      },
      "source": [
        "##2. Data Loader 선언\n",
        "\n",
        "\n",
        "1.   batch기반의 딥러닝 학습을 위해 mini batch 형성\n",
        "2.   dataset, batch size, shuffle, collate_fn\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def collate_batch(batch):\n",
        "  label_list, text_list = [], []\n",
        "  for (_label, _text) in batch:\n",
        "      label_list.append(label_transform(_label))\n",
        "      processed_text = torch.tensor(text_transform(_text))\n",
        "      text_list.append(processed_text)\n",
        "  return torch.tensor(label_list).to(device), pad_sequence(text_list, padding_value=3.0).to(device)\n",
        "\n",
        "train_iter = IMDB(split='train')"
      ],
      "metadata": {
        "id": "V9wXOZRgFU4u"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9ZE2mkfaKPAn"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#batch shape확인하기\n",
        "\n",
        "train_dataloader2 = DataLoader(list(train_iter), batch_size=32, shuffle=True, collate_fn=collate_batch)\n",
        "print(next(iter(train_dataloader2)))\n",
        "print(next(iter(train_dataloader2))[0])\n",
        "print(next(iter(train_dataloader2))[0].size())\n",
        "print(next(iter(train_dataloader2))[1].size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yDH8kW73oG7",
        "outputId": "15e727a7-b4dc-4216-b17f-baaedfa379a1"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1,\n",
            "        0, 0, 0, 0, 1, 0, 1, 1], device='cuda:0'), tensor([[    1,     1,     1,  ...,     1,     1,     1],\n",
            "        [    4,  3146,    40,  ..., 50535,    45, 22568],\n",
            "        [ 1505,  3147,    56,  ...,   919,   622,  1703],\n",
            "        ...,\n",
            "        [    3,     3,     3,  ...,     3,     3,     3],\n",
            "        [    3,     3,     3,  ...,     3,     3,     3],\n",
            "        [    3,     3,     3,  ...,     3,     3,     3]], device='cuda:0'))\n",
            "tensor([0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
            "        0, 0, 1, 1, 0, 0, 1, 0], device='cuda:0')\n",
            "torch.Size([32])\n",
            "torch.Size([845, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_tAoIcUMp3v"
      },
      "source": [
        "##3. Build Model\n",
        "- Embedding layer, RNN layer, Dropout layer, Fully-connected layer 로 이루어진 모델을 만듭니다.\n",
        "- 미리 학습된 워드 임베딩을 임베딩 레이어에 올립니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Jdh8JGOMyYq"
      },
      "source": [
        "class CustomModel(nn.Module):  # Custom model 정의\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, n_layers, dropout, pad_idx):\n",
        "        super().__init__()\n",
        "\n",
        "        # Define parameters\n",
        "        self.hidden_him = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        # Define Layers\n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx=pad_idx)\n",
        "\n",
        "        ### To-do ###\n",
        "        # Vanilla RNN layer\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim, n_layers, dropout=dropout)\n",
        "        # Dropout layer\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        ##################\n",
        "\n",
        "\n",
        "    def forward(self, text):\n",
        "\n",
        "        # text = [sent len, batch size]\n",
        "\n",
        "        embedded = self.embedding(text)\n",
        "\n",
        "        # embedded = [sent len, batch size, emb dim]\n",
        "        # embedded = [batch size, sent len, emb dim] if batch_first = True\n",
        "\n",
        "        # Apply RNN and Dropout\n",
        "        ### To-do ###\n",
        "        # Pass embedded layer into RNN\n",
        "        output, hidden = self.rnn(embedded)\n",
        "        #############\n",
        "        # hidden = [num_layers x num_directions, N, H]   H = hidden dimension\n",
        "\n",
        "        hidden = self.dropout(hidden[-1,:,:])\n",
        "\n",
        "        return self.fc(hidden)\n"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iz7u51ACdAF1"
      },
      "source": [
        "\n",
        "### 주의사항\n",
        "* nn.RNN 모델은 biderectional 의 경우 forward layer 와 backward layer 총 2개 레이어를 가지게 됩니다.\n",
        "*   Torch.nn 제공 RNN 모듈은 2개의 아웃풋 중 하나로 hidden state 을 출력하며,\n",
        "> `output, hidden = self.rnn(embedded)`\n",
        "*   `hidden`은 모델에 들어있는 **모든 레이어**의 last hidden state 을 출력합니다.\n",
        "*   따라서 `hidden` 의 형태는 `[num_layers x num_directions, batch_size, hidden_size]`가 됩니다.\n",
        "\n",
        "* 모델에서 총 n개의 layer 를 사용할 경우, 순서대로 _1번째 forward, 1번째 backward, 2번째 forward, 2번째 backward, ..., n번째 forward, n번째 backward_ 가 표시됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBD6lUpqe8eT"
      },
      "source": [
        "# To-do: Make Custom Bidirectional LSTM Model\n",
        "\n",
        "class CustomModel(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout, pad_idx):\n",
        "        super().__init__()\n",
        "\n",
        "        # Define parameters\n",
        "        self.hidden_him = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        # Define Layers\n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx=pad_idx)\n",
        "\n",
        "        ### To-do ###\n",
        "        # Bidirectional LSTM-RNN layer\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, bidirectional=bidirectional, dropout=dropout)\n",
        "        #############\n",
        "\n",
        "        # Dropout layer\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "        ### To-do ###\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(2*hidden_dim, output_dim)\n",
        "        #############\n",
        "\n",
        "\n",
        "    def forward(self, text):\n",
        "\n",
        "        # text = [sent len, batch size]\n",
        "\n",
        "        embedded = self.embedding(text)\n",
        "\n",
        "        # embedded = [sent len, batch size, emb dim]\n",
        "        # embedded = [batch size, sent len, emb dim] if batch_first = True\n",
        "\n",
        "        # Apply Bidirectional LSTM and Dropout\n",
        "        ### To-do ###\n",
        "        # Pass embedded layer into RNN\n",
        "        output, (hidden, cell) = self.lstm(embedded)\n",
        "        #############\n",
        "\n",
        "        # hidden = [num_layers x num_directions, N, H],  N=batch size, H = hidden dimension\n",
        "        hidden = self.dropout(torch.cat((hidden[-2,:,:],hidden[-1,:,:]),dim=1))\n",
        "        # hidden = [N, H]\n",
        "\n",
        "        return self.fc(hidden)\n"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9SlsITiYnLPI"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4EffzRaafEY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be453e97-408c-435d-db04-a847eb0c48af"
      },
      "source": [
        "INPUT_DIM = len(pretrained_embeddings)\n",
        "INPUT_DIM = len(vocab)\n",
        "print(INPUT_DIM)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.3\n",
        "PAD_IDX = new_stoi['<PAD>']\n",
        "print(PAD_IDX)\n",
        "model = CustomModel(INPUT_DIM,\n",
        "            EMBEDDING_DIM,\n",
        "            HIDDEN_DIM,\n",
        "            OUTPUT_DIM,\n",
        "            N_LAYERS,\n",
        "            BIDIRECTIONAL,\n",
        "            DROPOUT,\n",
        "            PAD_IDX)\n"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100686\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AJlOCYi6dLuS"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(type(pretrained_embeddings))\n",
        "# print(pretrained_embeddings.size())\n",
        "\n",
        "# model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "metadata": {
        "id": "UtXBMR5cLiq0"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCUKXn94afEf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "812b74c4-1897-4b11-f6ec-e3bb09984846"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)  # Count number of elements of all parameters\n",
        "\n",
        "print('The model has {:,} trainable parameters'.format(count_parameters(model)))"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 12,379,257 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDy-PGhSQcTd"
      },
      "source": [
        "## 4. Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09bHscfRG9ju"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())   # Gradient Descent 실행"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeZZ33ZeafEt"
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()  # 손실함수 정의"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bOa8C1tafEz"
      },
      "source": [
        "model = model.to(device)  #모델을 GPU 로 이동\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7exIxGaZafE4"
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer (Use torch.round() function)\n",
        "    round_preds = torch.round(torch.sigmoid(preds))\n",
        "\n",
        "    #count the correct by building list of 0/1\n",
        "    correct = (round_preds == y).float()\n",
        "\n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Eb16jU0afFA"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, batch_size):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.train()\n",
        "    cnt = math.ceil(len(iterator.dataset)/ batch_size)\n",
        "    #cnt = 782\n",
        "\n",
        "    for label, text in iterator:\n",
        "\n",
        "      # To-do\n",
        "      # Gradient 0으로 초기화\n",
        "      optimizer.zero_grad()\n",
        "      # Prediction\n",
        "      predictions = model(text).squeeze(1)\n",
        "\n",
        "      # Loss 계산\n",
        "      loss = criterion(predictions, label.float())\n",
        "\n",
        "      # Accuracy 계산\n",
        "      acc = binary_accuracy(predictions, label)\n",
        "      # Backward pass (gradient 계산)\n",
        "      loss.backward()\n",
        "      # Parameter update\n",
        "      optimizer.step()\n",
        "      epoch_loss += loss.item()\n",
        "      epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / cnt , epoch_acc / cnt"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8da_fbPRQ9I3"
      },
      "source": [
        "def evaluate(model, iterator, criterion, batch_size):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.eval()\n",
        "    cnt = math.ceil(len(iterator.dataset)/batch_size)\n",
        "    print(\"cnt\", cnt)\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for label, text in iterator:\n",
        "\n",
        "            predictions = model(text).squeeze(1)\n",
        "            loss = criterion(predictions, label.float())\n",
        "            acc = binary_accuracy(predictions, label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / cnt, epoch_acc / cnt\n"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZhS9Q2fSLyr"
      },
      "source": [
        "### *Do Training!*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uUWlVrUQ-lz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5efe625a-2d4c-4ec4-f55b-2219538da547"
      },
      "source": [
        "N_EPOCHS = 4\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "best_valid_loss = float('inf') # Represent infinity\n",
        "train_iter = IMDB(split='train')\n",
        "test_iter = IMDB(split='test')\n",
        "length = len(list(test_iter))\n",
        "train_list = list(train_iter)\n",
        "valid_list = list(test_iter)[int(0.5*length):]\n",
        "test_iter = IMDB(split='test')\n",
        "test_list = list(test_iter)[:int(0.5*length)]\n",
        "\n",
        "train_dataloader = DataLoader(train_list, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
        "valid_dataloader = DataLoader(test_list, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    train_loss, train_acc = train(model, train_dataloader , optimizer, criterion, BATCH_SIZE)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_dataloader, criterion, BATCH_SIZE)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'rnn-model.pt')\n",
        "\n",
        "    print('Epoch: {:02}'.format(epoch+1))\n",
        "    print('\\tTrain Loss: {:.3f} | Train Acc: {:.2f}%'.format(train_loss, train_acc*100))\n",
        "    print('\\t Val. Loss: {:.3f} |  Val. Acc: {:.2f}%'.format(valid_loss, valid_acc*100))"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cnt 391\n",
            "Epoch: 01\n",
            "\tTrain Loss: 0.665 | Train Acc: 58.58%\n",
            "\t Val. Loss: 0.510 |  Val. Acc: 98.26%\n",
            "cnt 391\n",
            "Epoch: 02\n",
            "\tTrain Loss: 0.464 | Train Acc: 78.22%\n",
            "\t Val. Loss: 0.256 |  Val. Acc: 87.60%\n",
            "cnt 391\n",
            "Epoch: 03\n",
            "\tTrain Loss: 0.267 | Train Acc: 89.35%\n",
            "\t Val. Loss: 0.237 |  Val. Acc: 90.31%\n",
            "cnt 391\n",
            "Epoch: 04\n",
            "\tTrain Loss: 0.173 | Train Acc: 93.61%\n",
            "\t Val. Loss: 0.275 |  Val. Acc: 89.81%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mXZ46wgRHWR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0ce2767-451f-404b-8689-489615c0fa3a"
      },
      "source": [
        "model.load_state_dict(torch.load('rnn-model.pt'))\n",
        "\n",
        "test_iterator = DataLoader(test_list, batch_size=32, shuffle=True, collate_fn=collate_batch)\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion, BATCH_SIZE)\n",
        "\n",
        "print('Test Loss: {:.3f} | Test Acc: {:.2f}%'.format(test_loss, test_acc*100))"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cnt 391\n",
            "Test Loss: 0.651 | Test Acc: 96.84%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EtTQaIdafFL"
      },
      "source": [
        "## 5. Test model\n",
        "우리가 직접 예문을 작성해서 트레인된 모델에서 예문을 어떻게 평가하는지 확인합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hxev65tafFQ"
      },
      "source": [
        "# 토크나이저로 spacy 를 사용합니다.\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "# 사용자가 입력한 sentence 를 훈련된 모델에 넣었을때의 결과값을 확인합니다.\n",
        "def predict_sentiment(model, sentence):\n",
        "    model.eval()\n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]  # Tokenization\n",
        "    tokenized = [tokens.lower() for tokens in tokenized]\n",
        "    print(tokenized)\n",
        "    indexed = [new_stoi[t] for t in tokenized]   # 위에서 만든 vocab 에 부여된 index 로 indexing\n",
        "    tensor = torch.LongTensor(indexed).to(device)   # indexing 된 sequence 를 torch tensor 형태로 만들어줌.\n",
        "    tensor = tensor.unsqueeze(1)   # 입력 텐서에 batch 차원을 만들어줌.\n",
        "    prediction = torch.sigmoid(model(tensor))  # 모델에 입력한 후 확률값 도출을 위한 sigmoid 적용\n",
        "    return prediction.item() # prediction 값 출력"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIk_EjmoSFdU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bca6e9c3-5348-4980-d2bb-9528b200a280"
      },
      "source": [
        "predict_sentiment(model, \"This film was bad\") #아주 낮은 값의 확률이 도출되는 것을 확인할 수 있습니다.(부정)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['this', 'film', 'was', 'bad']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.021375633776187897"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1ZZJbxaSFaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63fd87a8-21b5-416d-829f-5e6ef51f30eb"
      },
      "source": [
        "predict_sentiment(model, \"This film was great\") #아주 높은 값의 확률이 도출되는 것을 확인할 수 있습니다. (긍정)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['this', 'film', 'was', 'great']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6949607729911804"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDjerqMQRx9u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec210c55-b7c9-47ef-abc8-0c8692720670"
      },
      "source": [
        "predict_sentiment(model, \"This film was not good\")"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['this', 'film', 'was', 'not', 'good']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.015617698431015015"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_sentiment(model, \"This film was good\")"
      ],
      "metadata": {
        "id": "q-lZB0jhkUN_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d351fd70-1e53-49af-c35a-7737785a46ec"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['this', 'film', 'was', 'good']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8891170024871826"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rPdDULJhVoCp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}